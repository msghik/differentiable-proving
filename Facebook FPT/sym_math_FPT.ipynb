{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e84dfe046f054bee9184562aea8fa9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2216cd2d4e24a728481c570d73cbf0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1729207a96854af7ac7c3abe1f8a96c3",
              "IPY_MODEL_887354c702504e6ca802e3b8a48a9d2e"
            ]
          }
        },
        "c2216cd2d4e24a728481c570d73cbf0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1729207a96854af7ac7c3abe1f8a96c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_745b590ad3b645c197b7089cd03d2cb8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aced3c9cb2d34e8eb3d96ace1a6bdd07"
          }
        },
        "887354c702504e6ca802e3b8a48a9d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac2d7d048e024b9fb18049a0b2b7ff64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 2.67kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8914c87aec940f19e88c7a20e0b52ca"
          }
        },
        "745b590ad3b645c197b7089cd03d2cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aced3c9cb2d34e8eb3d96ace1a6bdd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac2d7d048e024b9fb18049a0b2b7ff64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8914c87aec940f19e88c7a20e0b52ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f57fe29117ce49c6a685b854496d41ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a93c12620df648c1833231e0f2891526",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e1a8f964caa43deb4cb11cec29d2e2e",
              "IPY_MODEL_780a0bf09eca49928b7121f16779ae0c"
            ]
          }
        },
        "a93c12620df648c1833231e0f2891526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e1a8f964caa43deb4cb11cec29d2e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17861c90f6324dfd9977a9d0a594152f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_519dec5293db4c79ada9857abeeb5cd5"
          }
        },
        "780a0bf09eca49928b7121f16779ae0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bab73fb105ff43218b287532faeda9b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:11&lt;00:00, 46.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ebf173a96ec46d6bb7119671f12ffea"
          }
        },
        "17861c90f6324dfd9977a9d0a594152f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "519dec5293db4c79ada9857abeeb5cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bab73fb105ff43218b287532faeda9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ebf173a96ec46d6bb7119671f12ffea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej9DcbIzExkt"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFecxNS10h9F",
        "outputId": "f6ed3b1e-6e01-40eb-916e-5231e3b8ff88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uu92TqU03DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935e783b-0aad-42dd-fe9a-e7bf227024ad"
      },
      "source": [
        "%cd 'drive/My Drive/SymbolicMath/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/SymbolicMath\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vBfzwKk05aj"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import sympy as sp\n",
        "import torch\n",
        "import random\n",
        "\n",
        "from src.utils import AttrDict\n",
        "from src.envs import build_env\n",
        "from src.model import build_modules\n",
        "\n",
        "from src.utils import to_cuda\n",
        "from src.envs.sympy_utils import simplify\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from functools import partial\n",
        "\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGjEb0MZLoR"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcO_qC0Y09PM"
      },
      "source": [
        "params = params = AttrDict({\n",
        "\n",
        "    # environment parameters\n",
        "    'env_name': 'char_sp',\n",
        "    'int_base': 10,\n",
        "    'balanced': False,\n",
        "    'positive': True,\n",
        "    'precision': 10,\n",
        "    'n_variables': 1,\n",
        "    'n_coefficients': 0,\n",
        "    'leaf_probs': '0.75,0,0.25,0',\n",
        "    'max_len': 512,\n",
        "    'max_int': 5,\n",
        "    'max_ops': 15,\n",
        "    'max_ops_G': 15,\n",
        "    'clean_prefix_expr': True,\n",
        "    'rewrite_functions': '',\n",
        "    'tasks': 'prim_fwd',\n",
        "    'operators': 'add:10,sub:3,mul:10,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:1,acos:1,atan:1,sinh:1,cosh:1,tanh:1,asinh:1,acosh:1,atanh:1',\n",
        "})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrigfFl4bce"
      },
      "source": [
        "env = build_env(params)         "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtoAgDxJA9Ap"
      },
      "source": [
        "def read_data(path):\n",
        "  with io.open(path, mode='r', encoding='utf-8') as f:\n",
        "    head = [next(f) for x in range(10000)]\n",
        "    lines = [line.rstrip().split('|') for line in head]\n",
        "    data = [xy.split('\\t') for _, xy in lines]\n",
        "    data = [xy for xy in data if len(xy) == 2]\n",
        "  return data\n",
        "\n",
        "path = 'prim_fwd.train'\n",
        "data = read_data(path)\n",
        "for i in range(len(data)):\n",
        "    data[i] = tuple([sent.split(\" \") for sent in data[i]])\n",
        "# data[0] would be like : \n",
        "# data[0]\n",
        "# [\"sub Y' pow x INT+ 2\", 'mul div INT+ 1 INT+ 3 pow x INT+ 3']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dyubL4RDAwy"
      },
      "source": [
        "def batch_sequences(x, y, env):\n",
        "      \"\"\"\n",
        "      Take as input a list of n sequences (torch.LongTensor vectors) and return\n",
        "      a tensor of size (slen, n) where slen is the length of the longest\n",
        "      sentence, and a vector lengths containing the length of each sentence.\n",
        "      \"\"\"\n",
        "      lengths_x = torch.LongTensor([len(s) + 2 for s in x])\n",
        "      lengths_y = torch.LongTensor([len(s) + 2 for s in y])\n",
        "      max_length = max(lengths_x.max().item(), lengths_y.max().item())\n",
        "      sent_x = torch.LongTensor(max_length , lengths_x.size(0)).fill_(env.pad_index)\n",
        "      sent_y = torch.LongTensor(max_length, lengths_y.size(0)).fill_(env.pad_index)\n",
        "      assert lengths_x.min().item() > 2\n",
        "      assert lengths_y.min().item() > 2\n",
        "\n",
        "      sent_x[0] = env.eos_index\n",
        "      for i, s in enumerate(x):\n",
        "          sent_x[1:lengths_x[i] - 1, i].copy_(s)\n",
        "          sent_x[lengths_x[i] - 1, i] = env.eos_index\n",
        "\n",
        "      sent_y[0] = env.eos_index\n",
        "      for i, s in enumerate(y):\n",
        "          sent_y[1:lengths_y[i] - 1, i].copy_(s)\n",
        "          sent_y[lengths_y[i] - 1, i] = env.eos_index\n",
        "\n",
        "      return sent_x, sent_y, max_length\n",
        "\n",
        "def collate_fn(elements):\n",
        "    \"\"\"\n",
        "    Collate samples into a batch.\n",
        "    \"\"\"\n",
        "    x, y = zip(*elements)\n",
        "    nb_ops = [sum(int(word in env.OPERATORS) for word in seq) for seq in x]\n",
        "    x = [torch.LongTensor([env.word2id[w] for w in seq if w in env.word2id]) for seq in x]\n",
        "    y = [torch.LongTensor([env.word2id[w] for w in seq if w in env.word2id]) for seq in y]\n",
        "    x, y, length = batch_sequences(x, y, env)\n",
        "    return (x, length), (y, length), torch.LongTensor(nb_ops)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag3h3MCFiimr"
      },
      "source": [
        "loader = DataLoader(data, batch_size = 25, shuffle= False, collate_fn=collate_fn)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLuoNsezE-6z"
      },
      "source": [
        "# Go through one loop\n",
        "counter = 0\n",
        "for (x, x_len), (y, y_len), nb_ops in loader:\n",
        "  print(f\"Iteration {counter}\")\n",
        "  print(\"Batched Input:\")\n",
        "  print(x, x_len)\n",
        "  print(\"Batched Labels:\")\n",
        "  print(y, y_len)\n",
        "  print(\"Batched Lengths:\")\n",
        "  print(nb_ops)\n",
        "  print(\"\")\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_rq-1BE8Iz8",
        "outputId": "f07a1346-bf2c-402f-d756-6de3f2f6366f"
      },
      "source": [
        "print('batched input shape:', x.shape)\n",
        "print('batched output shape:', y.shape)\n",
        "# each column is showing one training example"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batched input shape: torch.Size([26, 25])\n",
            "batched output shape: torch.Size([26, 25])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "e84dfe046f054bee9184562aea8fa9c3",
            "c2216cd2d4e24a728481c570d73cbf0b",
            "1729207a96854af7ac7c3abe1f8a96c3",
            "887354c702504e6ca802e3b8a48a9d2e",
            "745b590ad3b645c197b7089cd03d2cb8",
            "aced3c9cb2d34e8eb3d96ace1a6bdd07",
            "ac2d7d048e024b9fb18049a0b2b7ff64",
            "c8914c87aec940f19e88c7a20e0b52ca",
            "f57fe29117ce49c6a685b854496d41ea",
            "a93c12620df648c1833231e0f2891526",
            "2e1a8f964caa43deb4cb11cec29d2e2e",
            "780a0bf09eca49928b7121f16779ae0c",
            "17861c90f6324dfd9977a9d0a594152f",
            "519dec5293db4c79ada9857abeeb5cd5",
            "bab73fb105ff43218b287532faeda9b9",
            "4ebf173a96ec46d6bb7119671f12ffea"
          ]
        },
        "id": "yM4CtvOACS0Z",
        "outputId": "2791b93d-bc2d-4059-e791-ebca6564f569"
      },
      "source": [
        "gpt2 = GPT2Model.from_pretrained('gpt2')\n",
        "in_layer = nn.Embedding(len(env.word2id), 768)\n",
        "out_layer = nn.Linear(768, len(env.word2id)) # or flattening or softmax or non-linear !\n",
        "# [1, 45, 76, 2, 4] = ['sin', 'sub',...]\n",
        "# sin     sub     cos     add\n",
        "# 0.9     0.05   0.05       0  -> sin 0.9 =  1/sum(1+45+...)\n",
        "# 0       0.8     0.2       0 -> sub"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e84dfe046f054bee9184562aea8fa9c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f57fe29117ce49c6a685b854496d41ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.7.attn.masked_bias', 'h.3.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.5.attn.masked_bias', 'h.2.attn.masked_bias', 'h.1.attn.masked_bias', 'h.11.attn.masked_bias', 'h.10.attn.masked_bias', 'h.4.attn.masked_bias', 'h.6.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNWEZguM_MRq"
      },
      "source": [
        "for name, param in gpt2.named_parameters():\n",
        "    # freeze all parameters except the layernorm and positional embeddings\n",
        "    if 'ln' in name or 'wpe' in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv6bpBJ4_SJJ"
      },
      "source": [
        "parameters = list(gpt2.parameters()) + list(in_layer.parameters()) + list(out_layer.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr= 1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction = 'mean')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqj_gRsgabPQ"
      },
      "source": [
        "for layer in (gpt2, in_layer, out_layer):\n",
        "    layer.to(device=device)\n",
        "    layer.train()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OTvraO8fv8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdabaf1-2596-4b4a-bc83-1ad6caa8be8a"
      },
      "source": [
        "accuracies = list()\n",
        "num_epoch = 10\n",
        "for i in range(num_epoch):\n",
        "\n",
        "  random.shuffle(data)\n",
        "  \n",
        "  for (x, x_len), (y, y_len), nb_ops in loader:\n",
        "\n",
        "      x = x.to(device = device)\n",
        "      y = y.to(device = device)\n",
        "\n",
        "      embeddings = in_layer(x.reshape(x.shape[1], x.shape[0]))\n",
        "      hidden_state = gpt2(inputs_embeds=embeddings).last_hidden_state[:,:]\n",
        "      logits = out_layer(hidden_state)\n",
        "      logits = logits.reshape(logits.shape[0], logits.shape[2], logits.shape[1])\n",
        "      y = y.reshape(y.shape[1], y.shape[0])\n",
        "      loss = loss_fn(logits, y)\n",
        "\n",
        "      for i in range(logits.shape[0]):\n",
        "        accuracies.append((logits[i,:,:].argmax(dim=0) == y[i, :]).float().mean().item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      if len(accuracies) % 1000 == 0:\n",
        "          accuracy = sum(accuracies[-1000:]) / len(accuracies[-1000:])\n",
        "          print(f'Samples: {len(accuracies)}, Accuracy: {accuracy}')\n",
        "\n",
        "    \n",
        "print(f'Final accuracy: {sum(accuracies[-1000:]) / len(accuracies[-1000:])}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples: 1000, Accuracy: 0.19592539815977217\n",
            "Samples: 2000, Accuracy: 0.40781664416473357\n",
            "Samples: 3000, Accuracy: 0.43272654770500957\n",
            "Samples: 4000, Accuracy: 0.3982639718586579\n",
            "Samples: 5000, Accuracy: 0.4318989600948989\n",
            "Samples: 6000, Accuracy: 0.4368876083046198\n",
            "Samples: 7000, Accuracy: 0.41225662899948656\n",
            "Samples: 8000, Accuracy: 0.3801307040709071\n",
            "Samples: 9000, Accuracy: 0.4492217190936208\n",
            "Samples: 10000, Accuracy: 0.4383675733234268\n",
            "Samples: 11000, Accuracy: 0.43797356663644316\n",
            "Samples: 12000, Accuracy: 0.4185745967105031\n",
            "Samples: 13000, Accuracy: 0.40730757869035006\n",
            "Samples: 14000, Accuracy: 0.39377264042524623\n",
            "Samples: 15000, Accuracy: 0.41027901268424466\n",
            "Samples: 16000, Accuracy: 0.43389803647994996\n",
            "Samples: 17000, Accuracy: 0.4175436161486432\n",
            "Samples: 18000, Accuracy: 0.4378209162785206\n",
            "Samples: 19000, Accuracy: 0.4791283112252131\n",
            "Samples: 20000, Accuracy: 0.411519454682013\n",
            "Samples: 21000, Accuracy: 0.3958127555176616\n",
            "Samples: 22000, Accuracy: 0.42187587161245754\n",
            "Samples: 23000, Accuracy: 0.44992998252436517\n",
            "Samples: 24000, Accuracy: 0.4156330613968894\n",
            "Samples: 25000, Accuracy: 0.40665787662565706\n",
            "Samples: 26000, Accuracy: 0.42177115762606265\n",
            "Samples: 27000, Accuracy: 0.4180951241129078\n",
            "Samples: 28000, Accuracy: 0.39989163798466326\n",
            "Samples: 29000, Accuracy: 0.42421336234826595\n",
            "Samples: 30000, Accuracy: 0.4349907732214779\n",
            "Samples: 31000, Accuracy: 0.4593044520309195\n",
            "Samples: 32000, Accuracy: 0.3884550976725295\n",
            "Samples: 33000, Accuracy: 0.47587226015888157\n",
            "Samples: 34000, Accuracy: 0.4136230030013248\n",
            "Samples: 35000, Accuracy: 0.4573376333406195\n",
            "Samples: 36000, Accuracy: 0.3984083433893975\n",
            "Samples: 37000, Accuracy: 0.4054423409770243\n",
            "Samples: 38000, Accuracy: 0.42083427575370297\n",
            "Samples: 39000, Accuracy: 0.4182946217022836\n",
            "Samples: 40000, Accuracy: 0.4116054094629362\n",
            "Samples: 41000, Accuracy: 0.41230638650758195\n",
            "Samples: 42000, Accuracy: 0.42133185602002776\n",
            "Samples: 43000, Accuracy: 0.4534198342887685\n",
            "Samples: 44000, Accuracy: 0.431860576748848\n",
            "Samples: 45000, Accuracy: 0.4379655781770125\n",
            "Samples: 46000, Accuracy: 0.39671896098461\n",
            "Samples: 47000, Accuracy: 0.38425402268813924\n",
            "Samples: 48000, Accuracy: 0.42735007348190995\n",
            "Samples: 49000, Accuracy: 0.44511013755761086\n",
            "Samples: 50000, Accuracy: 0.4174919382778462\n",
            "Samples: 51000, Accuracy: 0.4010813394738361\n",
            "Samples: 52000, Accuracy: 0.44719021401926873\n",
            "Samples: 53000, Accuracy: 0.44943262137123385\n",
            "Samples: 54000, Accuracy: 0.4367272858787328\n",
            "Samples: 55000, Accuracy: 0.4448012776803225\n",
            "Samples: 56000, Accuracy: 0.4242591568026692\n",
            "Samples: 57000, Accuracy: 0.41686696535721424\n",
            "Samples: 58000, Accuracy: 0.44694909095391633\n",
            "Samples: 59000, Accuracy: 0.4233495898870751\n",
            "Samples: 60000, Accuracy: 0.43022531908983364\n",
            "Samples: 61000, Accuracy: 0.42256269554421305\n",
            "Samples: 62000, Accuracy: 0.39417647243663667\n",
            "Samples: 63000, Accuracy: 0.41470101655460895\n",
            "Samples: 64000, Accuracy: 0.44400121659273284\n",
            "Samples: 65000, Accuracy: 0.43717010494694114\n",
            "Samples: 66000, Accuracy: 0.42546089260093867\n",
            "Samples: 67000, Accuracy: 0.43125492173805835\n",
            "Samples: 68000, Accuracy: 0.3923370943944901\n",
            "Samples: 69000, Accuracy: 0.4042662147367373\n",
            "Samples: 70000, Accuracy: 0.3918569334642962\n",
            "Samples: 71000, Accuracy: 0.41874735230207444\n",
            "Samples: 72000, Accuracy: 0.4144878790527582\n",
            "Samples: 73000, Accuracy: 0.4222551710549742\n",
            "Samples: 74000, Accuracy: 0.4234255094733089\n",
            "Samples: 75000, Accuracy: 0.39486679574567823\n",
            "Samples: 76000, Accuracy: 0.41827961784554646\n",
            "Samples: 77000, Accuracy: 0.41368516910262404\n",
            "Samples: 78000, Accuracy: 0.43164732152130453\n",
            "Samples: 79000, Accuracy: 0.42353387775085866\n",
            "Samples: 80000, Accuracy: 0.4267437131190672\n",
            "Samples: 81000, Accuracy: 0.4286848070025444\n",
            "Samples: 82000, Accuracy: 0.40442823492921887\n",
            "Samples: 83000, Accuracy: 0.4186835772560444\n",
            "Samples: 84000, Accuracy: 0.40385970144486055\n",
            "Samples: 85000, Accuracy: 0.42103195080906153\n",
            "Samples: 86000, Accuracy: 0.4296739950478077\n",
            "Samples: 87000, Accuracy: 0.4153374583106488\n",
            "Samples: 88000, Accuracy: 0.39891101643024013\n",
            "Samples: 89000, Accuracy: 0.43174473109911193\n",
            "Samples: 90000, Accuracy: 0.44113651028834283\n",
            "Samples: 91000, Accuracy: 0.4200210292842239\n",
            "Samples: 92000, Accuracy: 0.44611711624776945\n",
            "Samples: 93000, Accuracy: 0.4175505297230557\n",
            "Samples: 94000, Accuracy: 0.4211233695363626\n",
            "Samples: 95000, Accuracy: 0.44610847293864936\n",
            "Samples: 96000, Accuracy: 0.40842573807947335\n",
            "Samples: 97000, Accuracy: 0.4343169953771867\n",
            "Samples: 98000, Accuracy: 0.36764366019913\n",
            "Samples: 99000, Accuracy: 0.43419829591177406\n",
            "Samples: 100000, Accuracy: 0.38631512542185376\n",
            "Final accuracy: 0.38631512542185376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icxLG9NT43xc",
        "outputId": "4ef17144-edf2-4a4a-b4fe-bac2e3cb0a17"
      },
      "source": [
        "print(f'Final accuracy: {sum(accuracies[-10000:]) / len(accuracies[-10000:])}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final accuracy: 0.41818203327194786\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}