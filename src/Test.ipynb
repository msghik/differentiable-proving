{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej9DcbIzExkt"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFecxNS10h9F",
        "outputId": "f309f612-32cd-43d4-da2c-dbf794904a7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uu92TqU03DT",
        "outputId": "0dfea95f-a698-4ac9-8aa8-cd2a08874e06"
      },
      "source": [
        "%cd 'drive/My Drive/SymbolicMath/'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/SymbolicMath/'\n",
            "/content/drive/My Drive/SymbolicMath\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vBfzwKk05aj"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import sympy as sp\n",
        "import torch\n",
        "\n",
        "from src.utils import AttrDict\n",
        "from src.envs import build_env\n",
        "from src.model import build_modules\n",
        "\n",
        "from src.utils import to_cuda\n",
        "from src.envs.sympy_utils import simplify\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from functools import partial\n",
        "\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcO_qC0Y09PM"
      },
      "source": [
        "params = params = AttrDict({\n",
        "\n",
        "    # environment parameters\n",
        "    'env_name': 'char_sp',\n",
        "    'int_base': 10,\n",
        "    'balanced': False,\n",
        "    'positive': True,\n",
        "    'precision': 10,\n",
        "    'n_variables': 1,\n",
        "    'n_coefficients': 0,\n",
        "    'leaf_probs': '0.75,0,0.25,0',\n",
        "    'max_len': 512,\n",
        "    'max_int': 5,\n",
        "    'max_ops': 15,\n",
        "    'max_ops_G': 15,\n",
        "    'clean_prefix_expr': True,\n",
        "    'rewrite_functions': '',\n",
        "    'tasks': 'prim_fwd',\n",
        "    'operators': 'add:10,sub:3,mul:10,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:1,acos:1,atan:1,sinh:1,cosh:1,tanh:1,asinh:1,acosh:1,atanh:1',\n",
        "})"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrigfFl4bce"
      },
      "source": [
        "env = build_env(params)         "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtoAgDxJA9Ap"
      },
      "source": [
        "def read_data(path):\n",
        "  with io.open(path, mode='r', encoding='utf-8') as f:\n",
        "    lines = [line.rstrip().split('|') for line in f]\n",
        "    data = [xy.split('\\t') for _, xy in lines]\n",
        "    data = [xy for xy in data if len(xy) == 2]\n",
        "  return data\n",
        "\n",
        "path = 'data/prim_fwd.txt'\n",
        "data = read_data(path)\n",
        "for i in range(len(data)):\n",
        "    data[i] = tuple([sent.split(\" \") for sent in data[i]])\n",
        "# data[0] would be like : \n",
        "# data[0]\n",
        "# [\"sub Y' pow x INT+ 2\", 'mul div INT+ 1 INT+ 3 pow x INT+ 3']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dyubL4RDAwy"
      },
      "source": [
        "def batch_sequences(sequences, env):\n",
        "      \"\"\"\n",
        "      Take as input a list of n sequences (torch.LongTensor vectors) and return\n",
        "      a tensor of size (slen, n) where slen is the length of the longest\n",
        "      sentence, and a vector lengths containing the length of each sentence.\n",
        "      \"\"\"\n",
        "      lengths = torch.LongTensor([len(s) + 2 for s in sequences])\n",
        "      sent = torch.LongTensor(lengths.max().item(), lengths.size(0)).fill_(env.pad_index)\n",
        "      assert lengths.min().item() > 2\n",
        "\n",
        "      sent[0] = env.eos_index\n",
        "      for i, s in enumerate(sequences):\n",
        "          sent[1:lengths[i] - 1, i].copy_(s)\n",
        "          sent[lengths[i] - 1, i] = env.eos_index\n",
        "\n",
        "      return sent, lengths\n",
        "\n",
        "def collate_fn(elements):\n",
        "    \"\"\"\n",
        "    Collate samples into a batch.\n",
        "    \"\"\"\n",
        "    x, y = zip(*elements)\n",
        "    nb_ops = [sum(int(word in env.OPERATORS) for word in seq) for seq in x]\n",
        "    x = [torch.LongTensor([env.word2id[w] for w in seq if w in env.word2id]) for seq in x]\n",
        "    y = [torch.LongTensor([env.word2id[w] for w in seq if w in env.word2id]) for seq in y]\n",
        "    x, x_len = batch_sequences(x, env)\n",
        "    y, y_len = batch_sequences(y, env)\n",
        "    return (x, x_len), (y, y_len), torch.LongTensor(nb_ops)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjD04WFvEMR7"
      },
      "source": [
        "loader = DataLoader(data, batch_size = 32, shuffle= False, collate_fn=collate_fn)\n",
        "# loader.dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLuoNsezE-6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dd286d-5ca0-4975-c814-40850e5150eb"
      },
      "source": [
        "# Go through one loop\n",
        "counter = 0\n",
        "for (x, x_len), (y, y_len), nb_ops in loader:\n",
        "  print(f\"Iteration {counter}\")\n",
        "  print(\"Batched Input:\")\n",
        "  print(x, x_len)\n",
        "  print(\"Batched Labels:\")\n",
        "  print(y, y_len)\n",
        "  print(\"Batched Lengths:\")\n",
        "  print(nb_ops)\n",
        "  print(\"\")\n",
        "  break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "Batched Input:\n",
            "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67,\n",
            "         67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67],\n",
            "        [79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
            "         79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79],\n",
            "        [55, 33, 53, 33, 55, 54, 54, 33, 53, 54, 33, 33, 54, 33, 33, 54, 54, 54,\n",
            "         54, 33, 54, 40, 53, 33, 33, 54, 33, 54, 54, 54, 54, 54],\n",
            "        [12, 12, 12, 12, 12, 71, 71, 12, 55, 12, 12, 54, 12, 54, 54, 12, 12, 12,\n",
            "         71, 55, 40, 33, 33, 12, 54, 55, 55, 55, 12, 55, 55, 47],\n",
            "        [71, 55,  0, 53, 47, 85, 90, 54, 12, 33, 28, 71, 65, 72, 71, 55, 33, 33,\n",
            "         85, 12, 12, 71, 71, 53, 72, 12, 12, 12, 33, 12, 71, 71],\n",
            "        [83, 12,  1, 12, 71, 55, 55, 71, 71, 12, 12, 83, 12, 82, 83, 33, 71, 66,\n",
            "         55, 71, 64, 82, 83, 54, 82, 71, 71, 71, 71, 71, 83, 82],\n",
            "        [ 0, 71,  1,  0, 86, 12, 12, 86, 84, 54,  0, 12,  0, 64, 12, 12, 82, 12,\n",
            "         12, 84, 12, 54, 12, 71, 12, 83, 83, 84, 82, 83, 47, 71],\n",
            "        [ 1, 84,  1,  1, 71, 72, 71, 55,  0, 72,  1, 38,  1, 12, 54, 55, 54, 54,\n",
            "         71, 64,  0, 71,  0, 84, 54, 40, 54, 65, 66, 48, 71, 90],\n",
            "        [ 1,  0,  1,  1, 83, 82, 83, 12,  1, 82,  1, 12,  1, 54, 71, 12, 71, 71,\n",
            "         86, 12,  1, 83,  1, 12, 72, 54, 72, 12, 12, 54, 82, 12],\n",
            "        [ 1,  1,  1,  1,  0,  0,  0, 71,  1, 55,  1,  0,  1, 71, 83, 71, 84, 83,\n",
            "          0,  0,  1, 12,  1,  0, 82, 71, 82,  0,  0, 72, 71,  0],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1, 83,  1, 12,  1,  1,  1, 83, 55, 84, 12, 12,\n",
            "          1,  1,  1,  0,  1,  1, 48, 83, 53,  1,  1, 83, 85,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  0,  1, 71,  1,  1,  1, 12, 12, 72,  0,  0,\n",
            "          1,  1,  1,  1,  1,  1, 12, 12, 12,  1,  1, 12, 55,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1, 83,  1,  1,  1,  0, 71, 82,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  0,  0,  0,  1,  1,  0, 12,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1, 84,  0,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 47,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 71,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 82,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 71,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 85,  1],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  1]]) tensor([ 8, 10,  6,  8, 11, 11, 11, 13,  9, 15,  8, 11,  8, 14, 16, 15, 13, 13,\n",
            "        11, 11,  9, 12,  9, 11, 14, 14, 14, 11, 11, 14, 20, 11])\n",
            "Batched Labels:\n",
            "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
            "        [54, 33, 33,  ..., 54, 54, 54],\n",
            "        [47, 54, 54,  ..., 47, 47, 47],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]]) tensor([12, 23, 11, 22, 15,  7,  9, 23, 14, 23, 29, 26, 12,  9, 17,  4, 17, 26,\n",
            "        12, 18, 13, 16, 23, 25, 18, 44, 22, 34, 26, 29, 24, 13])\n",
            "Batched Lengths:\n",
            "tensor([2, 3, 2, 3, 3, 3, 3, 4, 3, 5, 3, 4, 3, 5, 5, 5, 4, 5, 3, 4, 4, 4, 3, 4,\n",
            "        5, 5, 5, 4, 4, 5, 6, 3])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_rq-1BE8Iz8",
        "outputId": "687f7cdc-4df9-4461-fc3a-327f7de84585"
      },
      "source": [
        "print('batched input shape:', x.shape)\n",
        "print('batched output shape:', y.shape)\n",
        "# each column is showing one training example"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batched input shape: torch.Size([20, 32])\n",
            "batched output shape: torch.Size([44, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM4CtvOACS0Z",
        "outputId": "556e2610-5792-4a60-b29d-1c988f801f0a"
      },
      "source": [
        "gpt2 = GPT2Model.from_pretrained('gpt2')\n",
        "in_layer = nn.Embedding(1, 768)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNWEZguM_MRq"
      },
      "source": [
        "for name, param in gpt2.named_parameters():\n",
        "    # freeze all parameters except the layernorm and positional embeddings\n",
        "    if 'ln' in name or 'wpe' in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv6bpBJ4_SJJ"
      },
      "source": [
        "parameters = list(gpt2.parameters()) + list(in_layer.parameters())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAnX8k-x_bFz"
      },
      "source": [
        "for layer in (gpt2, in_layer):\n",
        "    layer.train()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Y40vgDX_po"
      },
      "source": [
        "emb_dim = 768\n",
        "proj = nn.Linear(emb_dim, params.n_words, bias=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOKeOvB_WqMX"
      },
      "source": [
        "def predict(tensor, pred_mask, y, get_scores, emb_dim):\n",
        "    \"\"\"\n",
        "    Given the last hidden state, compute word scores and/or the loss.\n",
        "        `pred_mask` is a ByteTensor of shape (slen, bs), filled with 1 when\n",
        "            we need to predict a word\n",
        "        `y` is a LongTensor of shape (pred_mask.sum(),)\n",
        "        `get_scores` is a boolean specifying whether we need to return scores\n",
        "    \"\"\"\n",
        "    x = tensor[pred_mask.unsqueeze(-1).expand_as(tensor)].view(-1, emb_dim)\n",
        "    assert (y == env.pad_index).sum().item() == 0\n",
        "    scores = proj(x).view(-1, len(env.id2word))\n",
        "    loss = F.cross_entropy(scores, y, reduction='mean')\n",
        "    return scores, loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwFTyRCkSKFm"
      },
      "source": [
        "def train_batch(x1, len1, x2, len2, params, emb_dim, optimizer):\n",
        "      \n",
        "      # target words to predict\n",
        "      alen = torch.arange(len2.max(), dtype=torch.long, device=len2.device)\n",
        "      pred_mask = alen[:, None] < len2[None] - 1  # do not predict anything given the last target word\n",
        "      y = x2[1:].masked_select(pred_mask[:-1])\n",
        "      assert len(y) == (len2 - 1).sum().item()\n",
        "\n",
        "      embeddings = in_layer(x.reshape(1, -1))\n",
        "      out = gpt2(inputs_embeds=embeddings)\n",
        "      _, loss = predict(tensor=out, pred_mask=pred_mask, y=y, get_scores=False, emb_dim = emb_dim)\n",
        "      print(loss.item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      # Calculate the gradients\n",
        "      loss.backward()\n",
        "      # Update the parameteres\n",
        "      optimizer.step()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rA-i8mSc_6VI",
        "outputId": "c15a5360-7c1b-407f-f1d3-6cba2f6d2736"
      },
      "source": [
        "optimizer = torch.optim.Adam(parameters)\n",
        "for (x, x_len), (y, y_len), nb_ops in loader:\n",
        "  train_batch(x, x_len, y, y_len, params, emb_dim, optimizer)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-9d05bde9723c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_ops\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-0cc66e3d7bcd>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(x1, len1, x2, len2, params, emb_dim, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.embedding(\n\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    }
  ]
}